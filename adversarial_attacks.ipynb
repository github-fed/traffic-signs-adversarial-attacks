{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Adversarial Attacks in Deep Learning\n",
    "\n",
    "Adversarial attacks are small, intentionally crafted perturbations added to input data with the goal of misleading machine learning models. These attacks expose the vulnerabilities of even the most accurate models and are crucial for understanding model robustness and improving defenses.\n",
    "\n",
    "In this notebook, I will experiment with several prominent adversarial attack methods:\n",
    "\n",
    "- **FGSM (Fast Gradient Sign Method)**: A single-step attack using the gradient of the loss with respect to the input.\n",
    "- **PGD (Projected Gradient Descent)**: An iterative and stronger version of FGSM.\n",
    "- **DeepFool**: A minimal perturbation method that pushes the input across the decision boundary.\n",
    "- **Carlini & Wagner Attack**: A powerful optimization-based attack targeting high-confidence misclassification.\n",
    "- **Adversarial Patch**: A physical-world attack that applies a visible patch to any image to cause misclassification.\n",
    "\n",
    "These experiments aim to highlight the behavior, effectiveness, and implications of each attack on neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_w5L_fvj2OO",
    "outputId": "a8d6ea4b-463a-4ae9-b94b-bcd2d54b19b7"
   },
   "outputs": [],
   "source": [
    "# Imports for plotting\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms.functional as TF\n",
    "from io import BytesIO\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from PIL import Image\n",
    "\n",
    "DATA_DIR = 'archive/DATA'\n",
    "TEST_DIR = 'archive/TEST'\n",
    "LABELS_CSV = 'archive/labels.csv'\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Adversarial Attacks\n",
    "\n",
    "Here is a short summary of the attack methods we will explore:\n",
    "\n",
    "- **FGSM (Fast Gradient Sign Method)**: This attack generates adversarial examples by taking a single step in the direction that increases the model's loss the most. It's fast and efficient, but relatively easy to defend against.\n",
    "\n",
    "- **PGD (Projected Gradient Descent)**: An iterative extension of FGSM that applies multiple small steps toward maximizing the loss, projecting the result back into a valid input space after each step. It's widely used to evaluate model robustness.\n",
    "\n",
    "- **DeepFool**: This method iteratively perturbs the input just enough to cross the model’s decision boundary. It aims for minimal distortion, often producing subtle but effective adversarial examples.\n",
    "\n",
    "- **Carlini & Wagner (C&W)**: A more advanced and powerful attack that formulates the attack as an optimization problem. It focuses on crafting perturbations that are hard to detect while ensuring high confidence in the wrong prediction.\n",
    "\n",
    "Each of these methods showcases different strategies and strengths, helping us understand how adversaries can exploit neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJWZfJjEj2OR"
   },
   "outputs": [],
   "source": [
    "def fast_gradient_sign_method(model, imgs, labels, epsilon=8/255, clip_min=0.0, clip_max=1.0):\n",
    "    device = imgs.device\n",
    "    model.eval()\n",
    "    imgs = imgs.clone().detach().requires_grad_(True)\n",
    "\n",
    "    logits = model(imgs)\n",
    "    loss = F.cross_entropy(logits, labels, reduction=\"sum\")  # same as −log p_y\n",
    "\n",
    "    grad = torch.autograd.grad(loss, imgs, only_inputs=True)[0]\n",
    "    pert = epsilon * grad.sign()\n",
    "\n",
    "    adv_imgs = torch.clamp(imgs + pert, clip_min, clip_max).detach()\n",
    "\n",
    "    return adv_imgs, pert.detach()\n",
    "\n",
    "\n",
    "def projected_gradient_descent(model, imgs, labels, epsilon=8/255, alpha=2/255, num_steps=10, random_start=True, clip_min=0.0, clip_max=1.0):\n",
    "    device = imgs.device\n",
    "    model.eval()\n",
    "\n",
    "    # Optional random start\n",
    "    if random_start:\n",
    "        delta = torch.empty_like(imgs).uniform_(-epsilon, epsilon)\n",
    "        adv = torch.clamp(imgs + delta, clip_min, clip_max)\n",
    "    else:\n",
    "        adv = imgs.clone()\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        adv = adv.detach().requires_grad_(True)\n",
    "\n",
    "        logits = model(adv)\n",
    "        loss = F.cross_entropy(logits, labels, reduction=\"sum\")\n",
    "\n",
    "        grad = torch.autograd.grad(loss, adv)[0]\n",
    "        adv = adv + alpha * grad.sign()\n",
    "\n",
    "        adv = torch.clamp(adv, imgs - epsilon, imgs + epsilon)\n",
    "        adv = torch.clamp(adv, clip_min, clip_max)\n",
    "\n",
    "    return adv.detach()\n",
    "\n",
    "\n",
    "def carlini_wagner(model, imgs, labels, targeted=False, c_init=1e-4, c_upper=1e10, binary_search_steps=9, kappa=0.0, num_steps=1000, lr=1e-2, early_abort=True):\n",
    "    device = imgs.device\n",
    "    n, _, _, _ = imgs.shape\n",
    "    n_classes = model(imgs[:1]).shape[1]\n",
    "\n",
    "    # Helper\n",
    "    def atanh(x): \n",
    "        return 0.5 * torch.log((1 + x) / (1 - x))\n",
    "\n",
    "    eps = 1e-6\n",
    "    imgs_clamped = imgs.clamp(eps, 1 - eps)\n",
    "    w_init = atanh(imgs_clamped * 2 - 1)\n",
    "    best_adv = imgs.clone()\n",
    "    best_l2 = torch.full((n,), float('inf'), device=device)\n",
    "\n",
    "    c_low = torch.zeros(n, device=device)\n",
    "    c_high = torch.full((n,), c_upper, device=device)\n",
    "    c = torch.full((n,), c_init, device=device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for bs_step in range(binary_search_steps):\n",
    "        w = torch.nn.Parameter(w_init.clone())\n",
    "        optim = torch.optim.Adam([w], lr=lr)\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            adv = torch.tanh(w) * 0.5 + 0.5\n",
    "            logits = model(adv)\n",
    "\n",
    "            one_hot = F.one_hot(labels, n_classes).float()\n",
    "            real = (one_hot * logits).sum(1)\n",
    "            other = ((1 - one_hot) * logits - 1e4 * one_hot).max(1).values\n",
    "\n",
    "            if targeted:\n",
    "                f = torch.clamp(other - real + kappa, min=0.)\n",
    "            else:\n",
    "                f = torch.clamp(real - other + kappa, min=0.)\n",
    "\n",
    "            l2 = (adv - imgs_clamped).view(n, -1).pow(2).sum(1)\n",
    "            loss = (c * f + l2).sum()\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            # Track best successful adv\n",
    "            with torch.no_grad():\n",
    "                mask = (f == 0) & (l2 < best_l2)\n",
    "                best_l2[mask] = l2[mask]\n",
    "                best_adv[mask] = adv[mask]\n",
    "\n",
    "            if early_abort and (f == 0).all():\n",
    "                break\n",
    "\n",
    "        # Update c via binary search\n",
    "        succeeded = best_l2 < float('inf')\n",
    "        c_high[succeeded] = torch.min(c_high[succeeded], c[succeeded])\n",
    "        c_low[~succeeded] = torch.max(c_low[~succeeded], c[~succeeded])\n",
    "        c = torch.where(c_high < 1e9, (c_low + c_high) / 2, c * 10)\n",
    "\n",
    "    perturb = best_adv - imgs\n",
    "    return best_adv.detach(), perturb.detach()\n",
    "\n",
    "\n",
    "def deepfool(model, imgs, num_steps=50, overshoot=0.02, max_classes=10):\n",
    "    device = imgs.device\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        orig_labels = model(imgs).argmax(1)\n",
    "\n",
    "    adv = imgs.clone().detach()\n",
    "    perturb = torch.zeros_like(adv)\n",
    "    batch, _ = imgs.shape[:2]\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        adv.requires_grad_(True)\n",
    "        logits = model(adv)\n",
    "        preds  = logits.argmax(1)\n",
    "\n",
    "        # stop if every sample changed label\n",
    "        if (preds != orig_labels).all():\n",
    "            break\n",
    "\n",
    "        grad_list = []\n",
    "        for idx in range(batch):\n",
    "            if preds[idx] != orig_labels[idx]:\n",
    "                grad_list.append(torch.zeros_like(adv[idx])) # already fooled\n",
    "                continue\n",
    "\n",
    "            # Select strongest `max_classes` logits to cut work\n",
    "            topk = torch.topk(logits[idx], max_classes).indices\n",
    "            grads = []\n",
    "            for k in topk:\n",
    "                grad = torch.autograd.grad(logits[idx, k], adv, retain_graph=True, create_graph=False)[0][idx]\n",
    "                grads.append(grad)\n",
    "\n",
    "            k0 = preds[idx].item()\n",
    "            grad0 = grads[topk.tolist().index(k0)]\n",
    "            min_ratio, best_r = float(\"inf\"), None\n",
    "\n",
    "            for g, k in zip(grads, topk):\n",
    "                if k == k0: continue\n",
    "                w_k = g - grad0\n",
    "                f_k = logits[idx, k] - logits[idx, k0]\n",
    "                ratio = f_k.abs() / (w_k.flatten().norm() + 1e-12)\n",
    "                if ratio < min_ratio:\n",
    "                    min_ratio, best_r = ratio, w_k\n",
    "\n",
    "            r_i = best_r / best_r.flatten().norm() * min_ratio\n",
    "            perturb[idx] += r_i\n",
    "            adv.data[idx] = imgs[idx] + (1 + overshoot) * perturb[idx]\n",
    "\n",
    "        adv = torch.clamp(adv.detach(), 0.0, 1.0)\n",
    "\n",
    "    adv_final = torch.clamp(imgs + (1 + overshoot) * perturb, 0.0, 1.0)\n",
    "    return adv_final.detach(), (adv_final - imgs).detach()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Description\n",
    "\n",
    "For my experiments, I use a **ResNet-34** convolutional neural network, provided by pytorch, a well-known architecture that incorporates residual connections to train deeper networks effectively. I trained the model on a dataset of **traffic signs**, enabling it to recognize and classify various road signs with high accuracy.\n",
    "\n",
    "This setup provides a realistic scenario to evaluate adversarial attacks, as traffic sign recognition is a critical task in safety-sensitive applications like autonomous driving. By testing different attacks on this model, we can analyze how adversarial examples might compromise real-world systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 8\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "\n",
    "print('Setting up data transformations...')\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "print('Loading datasets...')\n",
    "train_dataset = datasets.ImageFolder(DATA_DIR, transform=train_transform)\n",
    "# This part is sensetive to the dataset folder structure. Replace with your own if needed.\n",
    "\n",
    "# Sort folder names numerically\n",
    "sorted_classes = sorted(train_dataset.classes, key=lambda x: int(x))\n",
    "# Remap class_to_idx to match integer folder names\n",
    "train_dataset.class_to_idx = {cls_name: int(cls_name) for cls_name in sorted_classes}\n",
    "train_dataset.classes = sorted_classes  # optional, for consistency\n",
    "\n",
    "test_dataset = datasets.ImageFolder(TEST_DIR, transform=test_transform)\n",
    "test_dataset.class_to_idx = {cls_name: int(cls_name) for cls_name in sorted(test_dataset.classes, key=lambda x: int(x))}\n",
    "test_dataset.classes = sorted(test_dataset.classes, key=lambda x: int(x))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(f'Number of training samples: {len(train_dataset)}')\n",
    "print(f'Number of validation samples: {len(test_dataset)}')\n",
    "print(f'Number of classes: {len(train_dataset.classes)}')\n",
    "\n",
    "\n",
    "print('Loading ResNet34 model...')\n",
    "model = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "print('Starting training...')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'\\nEpoch {epoch+1}/{NUM_EPOCHS}')\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            print(f'[Batch {batch_idx+1}/{len(train_loader)}] Loss: {loss.item():.4f}')\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] Training Loss: {avg_loss:.4f}')\n",
    "\n",
    "    print('Starting validation...')\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] completed in {elapsed_time:.2f} seconds')\n",
    "\n",
    "print('Saving the model...')\n",
    "torch.save(model.state_dict(), 'models/resnet34_custom_fixed.pth')\n",
    "print('Model saved to models/resnet34_custom_fixed.pth ✅')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct Prediction Example\n",
    "\n",
    "The following example demonstrates a correctly classified traffic sign by the ResNet-34 model. This confirms that the model performs as expected on clean, unperturbed input data. It has overall 87% of accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model, transform, id_to_name, top_k=5, device='cpu'):\n",
    "    model.eval()\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        top_probs_tensor, top_indices_tensor = torch.topk(probs, top_k, dim=1)\n",
    "\n",
    "        returned_top_probs = top_probs_tensor.squeeze(0).cpu().numpy()\n",
    "        returned_top_indices = top_indices_tensor.squeeze(0).cpu().numpy()\n",
    "\n",
    "    print(f'Top {len(returned_top_probs)} predictions (from predict_image):')\n",
    "    for i in range(len(returned_top_probs)):\n",
    "        class_idx = int(returned_top_indices[i])\n",
    "        class_name = id_to_name.get(class_idx, f'Class {class_idx}')\n",
    "        prob = returned_top_probs[i]\n",
    "        print(f'  {i+1}: {class_name} ({prob*100:.2f}%)')\n",
    "    return returned_top_probs, returned_top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'models/resnet34_custom_fixed_1epochs.pth' # Path to your trained model\n",
    "IMAGE_PATH = 'archive/TEST/0/000_1_0005_1_j.png'\n",
    "TOP_K = 5 # Show top 5 predictions\n",
    "\n",
    "\n",
    "labels_df = pd.read_csv(LABELS_CSV)\n",
    "id_to_name = dict(zip(labels_df['ClassId'], labels_df['Name']))\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "print('Loading model...')\n",
    "model = resnet34(weights=None)\n",
    "num_classes = len(id_to_name)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "print(f'Loading image {IMAGE_PATH}...')\n",
    "image = Image.open(IMAGE_PATH).convert('RGB')\n",
    "print('Making prediction using predict_image function...')\n",
    "top_probs_np, top_indices_np = predict_image(image, model, transform, id_to_name, top_k=TOP_K, device=device)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "# Use the values returned by predict_image for the plot title\n",
    "predicted_class = id_to_name.get(int(top_indices_np[0]), 'Unknown')\n",
    "plt.title(f'Prediction: {predicted_class} ({top_probs_np[0]*100:.2f}%)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness to Random Perturbations\n",
    "\n",
    "In this example, I apply **random noise** and **JPEG compression** to the original image to test the model's robustness to common, non-adversarial distortions.\n",
    "\n",
    "As expected, these random modifications do not significantly affect the model's prediction. This demonstrates that standard perturbations—unlike carefully crafted adversarial ones—do not typically mislead the model, highlighting the targeted nature of adversarial attacks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original image\n",
    "img = Image.open(IMAGE_PATH).convert('RGB')\n",
    "\n",
    "# Add random noise\n",
    "img_np = np.array(img).astype(np.float32) / 255.0\n",
    "noise = np.random.normal(0, 0.05, img_np.shape)\n",
    "img_noisy = np.clip(img_np + noise, 0, 1)\n",
    "img_noisy_pil = Image.fromarray((img_noisy * 255).astype(np.uint8))\n",
    "print(\"\\nPredictions with random noise:\")\n",
    "predict_image(img_noisy_pil, model, transform, id_to_name, top_k=TOP_K, device=device)\n",
    "\n",
    "buffer = BytesIO()\n",
    "img.save(buffer, format='JPEG', quality=30)\n",
    "buffer.seek(0)\n",
    "img_jpeg = Image.open(buffer)\n",
    "print(\"\\nPredictions with JPEG compression (quality=30):\")\n",
    "predict_image(img_jpeg, model, transform, id_to_name, top_k=TOP_K, device=device)\n",
    "# Set subplot titles to model predictions\n",
    "def get_pred_title(img):\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        top_prob, top_idx = torch.max(probs, dim=1)\n",
    "        class_name = id_to_name.get(int(top_idx.item()), f'Class {top_idx.item()}')\n",
    "        return f\"{class_name}\\n({top_prob.item()*100:.2f}%)\"\n",
    "\n",
    "# Show all three images side by side\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axs[0].imshow(img_noisy_pil)\n",
    "axs[0].set_title(f\"Random Noise:\\n {get_pred_title(img_noisy_pil)}\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(img_jpeg)\n",
    "axs[1].set_title(f\"JPEG (q=30):\\n {get_pred_title(img_jpeg)}\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attack Results\n",
    "\n",
    "Below, I show the effect of different adversarial attacks on a correctly classified traffic sign. Each attack modifies the original image just enough to deceive the model, causing it to misclassify the sign with varying confidence levels.\n",
    "\n",
    "- **FGSM** leads to a correct classification as \"Speed limit (5km/h)\" but with much lower confidence, and the top-5 predictions are close variations of speed limit signs.\n",
    "- **PGD** is significantly more aggressive, confidently misclassifying the image as \"Go Right\" with 98.28% confidence—completely unrelated to the original class.\n",
    "- **CW (Carlini & Wagner)** and **DeepFool** produce more subtle perturbations, both leading to a misclassification as \"Speed limit (40km/h)\", which is a plausible mistake, but still incorrect.\n",
    "\n",
    "These results highlight how even imperceptible changes can fool the model, and how the type of attack affects both the confidence and nature of the misclassification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the image (reuse IMAGE_PATH, transform, device)\n",
    "img = Image.open(IMAGE_PATH).convert('RGB')\n",
    "img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "# Get the true label if available, otherwise pick the top-1 prediction as label\n",
    "with torch.no_grad():\n",
    "    output = model(img_tensor)\n",
    "    pred_label = output.argmax(dim=1)\n",
    "\n",
    "# FGSM attack\n",
    "adv_img_fgsm, _ = fast_gradient_sign_method(model, img_tensor, pred_label, epsilon=0.02)\n",
    "\n",
    "# PGD attack\n",
    "adv_img_pgd = projected_gradient_descent(model, img_tensor, pred_label, epsilon=0.02, alpha=0.01, num_steps=10)\n",
    "\n",
    "# Carlini-Wagner attack\n",
    "adv_img_cw, _ = carlini_wagner(model, img_tensor, pred_label, targeted=False, kappa=0.0, num_steps=200, lr=5e-2)\n",
    "\n",
    "# DeepFool attack\n",
    "adv_img_deepfool, _ = deepfool(model, img_tensor, num_steps=20, overshoot=0.02)\n",
    "\n",
    "# Get predictions for the adversarial images\n",
    "def get_topk_preds(img_adv):\n",
    "    with torch.no_grad():\n",
    "        adv_output = model(img_adv)\n",
    "        adv_probs = torch.softmax(adv_output, dim=1)\n",
    "        adv_top_probs, adv_top_indices = torch.topk(adv_probs, TOP_K)\n",
    "        adv_top_probs = adv_top_probs.squeeze().cpu().numpy()\n",
    "        adv_top_indices = adv_top_indices.squeeze().cpu().numpy()\n",
    "    return adv_top_probs, adv_top_indices\n",
    "\n",
    "adv_top_probs_fgsm, adv_top_indices_fgsm = get_topk_preds(adv_img_fgsm)\n",
    "adv_top_probs_pgd, adv_top_indices_pgd = get_topk_preds(adv_img_pgd)\n",
    "adv_top_probs_cw, adv_top_indices_cw = get_topk_preds(adv_img_cw)\n",
    "adv_top_probs_deepfool, adv_top_indices_deepfool = get_topk_preds(adv_img_deepfool)\n",
    "\n",
    "print('FGSM Adversarial top predictions:')\n",
    "for i in range(TOP_K):\n",
    "    class_idx = int(adv_top_indices_fgsm[i])\n",
    "    class_name = id_to_name.get(class_idx, f'Class {class_idx}')\n",
    "    prob = adv_top_probs_fgsm[i]\n",
    "    print(f'  {i+1}: {class_name} ({prob*100:.2f}%)')\n",
    "\n",
    "print('\\nPGD Adversarial top predictions:')\n",
    "for i in range(TOP_K):\n",
    "    class_idx = int(adv_top_indices_pgd[i])\n",
    "    class_name = id_to_name.get(class_idx, f'Class {class_idx}')\n",
    "    prob = adv_top_probs_pgd[i]\n",
    "    print(f'  {i+1}: {class_name} ({prob*100:.2f}%)')\n",
    "\n",
    "print('\\nCW Adversarial top predictions:')\n",
    "for i in range(TOP_K):\n",
    "    class_idx = int(adv_top_indices_cw[i])\n",
    "    class_name = id_to_name.get(class_idx, f'Class {class_idx}')\n",
    "    prob = adv_top_probs_cw[i]\n",
    "    print(f'  {i+1}: {class_name} ({prob*100:.2f}%)')\n",
    "\n",
    "print('\\nDeepFool Adversarial top predictions:')\n",
    "for i in range(TOP_K):\n",
    "    class_idx = int(adv_top_indices_deepfool[i])\n",
    "    class_name = id_to_name.get(class_idx, f'Class {class_idx}')\n",
    "    prob = adv_top_probs_deepfool[i]\n",
    "    print(f'  {i+1}: {class_name} ({prob*100:.2f}%)')\n",
    "\n",
    "# Visualize images\n",
    "fig, axs = plt.subplots(1, 4, figsize=(14, 4))\n",
    "\n",
    "# Original prediction\n",
    "with torch.no_grad():\n",
    "    orig_probs = torch.softmax(output, dim=1)\n",
    "    orig_top_prob, orig_top_idx = torch.max(orig_probs, dim=1)\n",
    "    orig_class_name = id_to_name.get(int(orig_top_idx.item()), f'Class {orig_top_idx.item()}')\n",
    "    orig_prob = orig_top_prob.item()\n",
    "\n",
    "# FGSM adversarial image\n",
    "adv_class_name_fgsm = id_to_name.get(int(adv_top_indices_fgsm[0]), f'Class {adv_top_indices_fgsm[0]}')\n",
    "adv_prob_fgsm = adv_top_probs_fgsm[0]\n",
    "adv_img_disp_fgsm = adv_img_fgsm.squeeze().detach().cpu().permute(1, 2, 0).numpy().clip(0, 1)\n",
    "axs[0].imshow(adv_img_disp_fgsm)\n",
    "axs[0].set_title(f'FGSM:\\n{adv_class_name_fgsm} ({adv_prob_fgsm*100:.2f}%)')\n",
    "axs[0].axis('off')\n",
    "\n",
    "# PGD adversarial image\n",
    "adv_class_name_pgd = id_to_name.get(int(adv_top_indices_pgd[0]), f'Class {adv_top_indices_pgd[0]}')\n",
    "adv_prob_pgd = adv_top_probs_pgd[0]\n",
    "adv_img_disp_pgd = adv_img_pgd.squeeze().detach().cpu().permute(1, 2, 0).numpy().clip(0, 1)\n",
    "axs[1].imshow(adv_img_disp_pgd)\n",
    "axs[1].set_title(f'PGD:\\n{adv_class_name_pgd} ({adv_prob_pgd*100:.2f}%)')\n",
    "axs[1].axis('off')\n",
    "\n",
    "# CW adversarial image\n",
    "adv_class_name_cw = id_to_name.get(int(adv_top_indices_cw[0]), f'Class {adv_top_indices_cw[0]}')\n",
    "adv_prob_cw = adv_top_probs_cw[0]\n",
    "adv_img_disp_cw = adv_img_cw.squeeze().detach().cpu().permute(1, 2, 0).numpy().clip(0, 1)\n",
    "axs[2].imshow(adv_img_disp_cw)\n",
    "axs[2].set_title(f'CW:\\n{adv_class_name_cw} ({adv_prob_cw*100:.2f}%)')\n",
    "axs[2].axis('off')\n",
    "\n",
    "# DeepFool adversarial image\n",
    "adv_class_name_deepfool = id_to_name.get(int(adv_top_indices_deepfool[0]), f'Class {adv_top_indices_deepfool[0]}')\n",
    "adv_prob_deepfool = adv_top_probs_deepfool[0]\n",
    "adv_img_disp_deepfool = adv_img_deepfool.squeeze().detach().cpu().permute(1, 2, 0).numpy().clip(0, 1)\n",
    "axs[3].imshow(adv_img_disp_deepfool)\n",
    "axs[3].set_title(f'DeepFool:\\n{adv_class_name_deepfool} ({adv_prob_deepfool*100:.2f}%)')\n",
    "axs[3].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating an Adversarial Patch\n",
    "\n",
    "In this section, I generate an **adversarial patch**—a localized and visible perturbation designed to be overlaid onto any input image. Unlike other attacks that apply subtle noise across the entire image, patch attacks aim to create a universal and transferable trigger that causes misclassification regardless of the image content or context.\n",
    "\n",
    "The code below optimizes the patch using the model's gradients to maximize the prediction confidence for a specific target class. Once trained, this patch can be applied to different images to consistently fool the model into making incorrect predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adversarial_patch(model, dataloader, target_class, patch_size=(50, 50), image_size=(224, 224), num_epochs=20, batch_size_patch_opt=16,\n",
    "    learning_rate=0.01,\n",
    "    max_rotation_angle=15.0,\n",
    "    scale_range=(0.1, 0.3),\n",
    "    device=None,\n",
    "    verbose=True\n",
    "):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False # Freeze model parameters\n",
    "\n",
    "    patch = torch.rand(1, 3, patch_size[0], patch_size[1], device=device, requires_grad=True)\n",
    "    optimizer = optim.Adam([patch], lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Starting adversarial patch generation on {device}...\")\n",
    "        print(f\"Target class: {target_class}, Patch size: {patch_size}, Image size: {image_size}\")\n",
    "        print(f\"Epochs: {num_epochs}, LR: {learning_rate}, Batch size for patch opt: {batch_size_patch_opt}\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        batches_processed = 0\n",
    "        for i, (images, _) in enumerate(dataloader):\n",
    "            if images.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            current_batch_size = min(images.shape[0], batch_size_patch_opt)\n",
    "            if images.shape[0] < batch_size_patch_opt and verbose and i==0 and epoch==0:\n",
    "                print(f\"Warning: Dataloader batch size ({images.shape[0]}) is less than \"\n",
    "                      f\"batch_size_patch_opt ({batch_size_patch_opt}). \"\n",
    "                      \"Patch gradients will be averaged over smaller batches.\")\n",
    "\n",
    "\n",
    "            images_subset = images[:current_batch_size].to(device)\n",
    "            patched_images_for_batch = []\n",
    "\n",
    "            for img_idx in range(images_subset.shape[0]):\n",
    "                original_image = images_subset[img_idx:img_idx+1].clone()\n",
    "                \n",
    "                scale_factor = random.uniform(scale_range[0], scale_range[1])\n",
    "                scaled_patch_height = int(image_size[0] * scale_factor)\n",
    "                # Maintain aspect ratio of the initial patch_size for scaling\n",
    "                scaled_patch_width = int(patch_size[1] * (scaled_patch_height / patch_size[0])) \n",
    "                if scaled_patch_height <=0 or scaled_patch_width <=0: # Safety check\n",
    "                    scaled_patch_height = max(1, scaled_patch_height)\n",
    "                    scaled_patch_width = max(1, scaled_patch_width)\n",
    "\n",
    "                current_patch_scaled = TF.resize(patch, (scaled_patch_height, scaled_patch_width), antialias=True)\n",
    "                angle = random.uniform(-max_rotation_angle, max_rotation_angle)\n",
    "                \n",
    "                rotated_patch = TF.rotate(current_patch_scaled, angle, fill=0.0, expand=False) \n",
    "                patch_mask = torch.ones_like(rotated_patch, device=device)\n",
    "\n",
    "                # Random location\n",
    "                max_y = image_size[0] - rotated_patch.shape[2] # height\n",
    "                max_x = image_size[1] - rotated_patch.shape[3] # width\n",
    "                \n",
    "                loc_y = random.randint(0, max(0, max_y))\n",
    "                loc_x = random.randint(0, max(0, max_x))\n",
    "\n",
    "                patched_image = original_image.clone()\n",
    "                \n",
    "                # Define the region in the image\n",
    "                # Ensure slices don't go out of bounds\n",
    "                end_y = loc_y + rotated_patch.shape[2]\n",
    "                end_x = loc_x + rotated_patch.shape[3]\n",
    "                \n",
    "                # Simple overlay:\n",
    "                patched_image[0, :, loc_y:end_y, loc_x:end_x] = rotated_patch[0]\n",
    "                \n",
    "                patched_images_for_batch.append(patched_image)\n",
    "\n",
    "            if not patched_images_for_batch:\n",
    "                continue\n",
    "\n",
    "            patched_images_tensor = torch.cat(patched_images_for_batch, dim=0).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(patched_images_tensor)\n",
    "            target_labels = torch.full((patched_images_tensor.shape[0],), target_class,\n",
    "                                       dtype=torch.long, device=device)\n",
    "            loss = criterion(outputs, target_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                patch.data.clamp_(0.0, 1.0)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            batches_processed +=1\n",
    "            \n",
    "            if verbose and (i % 10 == 0 or i == len(dataloader) - 1):\n",
    "                 print(f\"  [Epoch {epoch+1}/{num_epochs}, Batch {i+1}/{len(dataloader)}] Current Batch Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        if batches_processed > 0:\n",
    "            avg_epoch_loss = running_loss / batches_processed\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs} - Average Patch Loss: {avg_epoch_loss:.4f}\")\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs} - No batches processed in this epoch.\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Adversarial patch generation finished.\")\n",
    "    return patch.detach()\n",
    "\n",
    "\n",
    "DATA_DIR_FOR_PATCH_GEN = \"archive/DATA\"\n",
    "MODEL_PATH = \"models/resnet34_custom_fixed_1epochs.pth\"\n",
    "TARGET_CLASS_IDX = 14 # Choose a valid class index from your dataset\n",
    "OUTPUT_PATCH_FILENAME = \"generated_adversarial_patch.png\"\n",
    "USER_BATCH_SIZE = 32 # Batch size for loading background images\n",
    "USER_NUM_WORKERS = 8\n",
    "PATCH_SIZE_HW = (50, 50) # Size of the patch to be generated\n",
    "MODEL_IMG_SIZE_HW = (224, 224) # Image size your model expects\n",
    "NUM_PATCH_EPOCHS = 1 # Number of epochs to train the patch\n",
    "PATCH_OPT_BATCH_SIZE = 16 # Number of images from dataloader to use for each patch update step. Ensure USER_BATCH_SIZE >= PATCH_OPT_BATCH_SIZE is reasonable or handle appropriately\n",
    "PATCH_LR = 0.01\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "background_image_transform = transforms.Compose([\n",
    "    transforms.Resize(MODEL_IMG_SIZE_HW),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "if not os.path.isdir(DATA_DIR_FOR_PATCH_GEN):\n",
    "    print(f\"Error: DATA_DIR_FOR_PATCH_GEN '{DATA_DIR_FOR_PATCH_GEN}' not found. Please set the correct path.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loading background images from: {DATA_DIR_FOR_PATCH_GEN}\")\n",
    "background_dataset = datasets.ImageFolder(DATA_DIR_FOR_PATCH_GEN, transform=background_image_transform)\n",
    "\n",
    "try:\n",
    "    sorted_classes_bg = sorted(background_dataset.classes, key=lambda x: int(x))\n",
    "    background_dataset.class_to_idx = {cls_name: int(cls_name) for cls_name in sorted_classes_bg}\n",
    "    background_dataset.classes = sorted_classes_bg\n",
    "    print(f\"Background dataset classes (sorted and re-indexed): {background_dataset.classes}\")\n",
    "except ValueError:\n",
    "    print(\"Warning: Could not sort background dataset classes numerically. Using default ImageFolder ordering.\")\n",
    "    print(f\"Background dataset classes: {background_dataset.classes}\")\n",
    "\n",
    "\n",
    "background_loader = DataLoader(background_dataset, batch_size=USER_BATCH_SIZE, shuffle=True, num_workers=USER_NUM_WORKERS)\n",
    "\n",
    "num_available_classes = len(background_dataset.classes)\n",
    "print(f\"Number of classes in background dataset: {num_available_classes}\")\n",
    "\n",
    "if not (0 <= TARGET_CLASS_IDX < num_available_classes):\n",
    "    print(f\"Error: TARGET_CLASS_IDX {TARGET_CLASS_IDX} is out of range for {num_available_classes} classes.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loading model: {MODEL_PATH}\")\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"Error: Model path '{MODEL_PATH}' not found. Please set the correct path.\")\n",
    "    exit()\n",
    "    \n",
    "model_to_attack = resnet34(weights=None)\n",
    "model_to_attack.fc = nn.Linear(model_to_attack.fc.in_features, num_available_classes)\n",
    "\n",
    "try:\n",
    "    model_to_attack.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    print(\"Model state loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model state_dict: {e}\")\n",
    "    print(\"Ensure num_classes used for model.fc matches the saved model.\")\n",
    "    exit()\n",
    "    \n",
    "model_to_attack = model_to_attack.to(device)\n",
    "model_to_attack.eval() # Ensure model is in eval mode\n",
    "\n",
    "print(\"\\nStarting adversarial patch generation process...\")\n",
    "start_patch_time = time.time()\n",
    "\n",
    "adversarial_patch = generate_adversarial_patch(\n",
    "    model=model_to_attack,\n",
    "    dataloader=background_loader,\n",
    "    target_class=TARGET_CLASS_IDX,\n",
    "    patch_size=PATCH_SIZE_HW,\n",
    "    image_size=MODEL_IMG_SIZE_HW,\n",
    "    num_epochs=NUM_PATCH_EPOCHS,\n",
    "    batch_size_patch_opt=PATCH_OPT_BATCH_SIZE,\n",
    "    learning_rate=PATCH_LR,\n",
    "    device=device,\n",
    "    verbose=True\n",
    ")\n",
    "end_patch_time = time.time()\n",
    "print(f\"Adversarial patch generation took {end_patch_time - start_patch_time:.2f} seconds.\")\n",
    "\n",
    "if adversarial_patch is not None:\n",
    "    print(f\"\\nAdversarial patch generated successfully (shape: {adversarial_patch.shape}).\")\n",
    "    try:\n",
    "        save_image(adversarial_patch.squeeze(0).cpu(), OUTPUT_PATCH_FILENAME)\n",
    "        print(f\"Saved generated patch to '{OUTPUT_PATCH_FILENAME}'\")\n",
    "    except ImportError:\n",
    "        print(\"torchvision.utils.save_image not available. Cannot save patch image.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving patch image: {e}\")\n",
    "else:\n",
    "    print(\"Adversarial patch generation failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the Adversarial Patch\n",
    "\n",
    "To demonstrate the effect of the adversarial patch, we randomly place it on the input image. While more advanced techniques may optimize the patch's location, this simple approach already reveals its effectiveness.\n",
    "\n",
    "Despite the randomness, the patch often causes the model to misclassify the image with high confidence, highlighting the robustness and transferability of the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_patch_to_image(image_path, patch, patch_size=32):\n",
    "    # Load and preprocess the image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = img.resize((224, 224))\n",
    "    img_np = np.array(img).astype(np.float32) / 255.0\n",
    "\n",
    "    if isinstance(patch, torch.Tensor):\n",
    "        patch_disp = (torch.tanh(patch) + 1) / 2 if patch.min() < 0 or patch.max() > 1 else patch\n",
    "        patch_disp = patch_disp.detach().cpu().permute(1, 2, 0).numpy()\n",
    "        patch_disp = np.clip(patch_disp, 0, 1)\n",
    "    else:\n",
    "        patch_disp = patch\n",
    "\n",
    "    if isinstance(patch_disp, np.ndarray):\n",
    "        h_patch, w_patch = patch_disp.shape[:2]\n",
    "    elif isinstance(patch_disp, Image.Image):\n",
    "        w_patch, h_patch = patch_disp.size\n",
    "        patch_disp = np.array(patch_disp).astype(np.float32) / 255.0\n",
    "    else:\n",
    "        raise TypeError(\"patch_disp must be a numpy array or PIL Image.\")\n",
    "\n",
    "    if h_patch != patch_size or w_patch != patch_size:\n",
    "        patch_disp = np.array(Image.fromarray((patch_disp * 255).astype(np.uint8)).resize((patch_size, patch_size)))\n",
    "        patch_disp = patch_disp.astype(np.float32) / 255.0\n",
    "\n",
    "    h, w, _ = img_np.shape\n",
    "    if h - patch_size > 0:\n",
    "        y1 = np.random.randint(0, h - patch_size + 1)\n",
    "    else:\n",
    "        y1 = 0\n",
    "    if w - patch_size > 0:\n",
    "        x1 = np.random.randint(0, w - patch_size + 1)\n",
    "    else:\n",
    "        x1 = 0\n",
    "    y2 = y1 + patch_size\n",
    "    x2 = x1 + patch_size\n",
    "    y2 = min(y2, h)\n",
    "    x2 = min(x2, w)\n",
    "    img_np[y1:y2, x1:x2, :] = patch_disp[:y2 - y1, :x2 - x1, :]\n",
    "\n",
    "    # Convert back to PIL Image for display or saving\n",
    "    img_with_patch = Image.fromarray((img_np * 255).astype(np.uint8))\n",
    "\n",
    "    return img_with_patch\n",
    "\n",
    "\n",
    "image_path = \"archive/TEST/1/001_0006_j.png\"  # Replace with your image path\n",
    "patch_path = \"generated_adversarial_patch.png\"  # Replace with your patch path\n",
    "patch = Image.open(patch_path).convert('RGB')\n",
    "patched_img = add_patch_to_image(image_path, patch, patch_size=50)\n",
    "patched_img.show()\n",
    "\n",
    "patched_img.save(\"patched_output.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with Adversarial Patch vs. Black Patch\n",
    "\n",
    "In this section, I evaluate the impact of the adversarial patch on the model's prediction. When the patch is applied to the image, the model is successfully fooled and misclassifies the input with high confidence—demonstrating the attack's effectiveness.\n",
    "\n",
    "To further validate that the misclassification is not simply due to occasion, we replace the adversarial patch with a **black (non-informative) patch** at the exact same location. The model still correctly classifies the image in this case, confirming that the adversarial patch's structure—not just its presence—is responsible for misleading the model.\n",
    "\n",
    "This comparison illustrates how adversarial patches can hijack the model’s attention and produce targeted misclassifications, even when applied randomly and visibly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'models/resnet34_custom_fixed_1epochs.pth' # Path to your trained model\n",
    "IMAGE_PATH = 'patched_output.jpg'\n",
    "FAKE_PATCH_PATH = 'fake_patch.png'\n",
    "\n",
    "print(f'Loading image {IMAGE_PATH}...')\n",
    "image = Image.open(IMAGE_PATH).convert('RGB')\n",
    "fake_patch_image = Image.open(FAKE_PATCH_PATH).convert('RGB')\n",
    "\n",
    "# Preprocess both images\n",
    "input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "fake_patch_tensor = transform(fake_patch_image).unsqueeze(0).to(device)\n",
    "\n",
    "# Get predictions for both images\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_tensor)\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "    top_probs, top_indices = torch.topk(probabilities, TOP_K)\n",
    "    top_probs = top_probs.squeeze().cpu().numpy()\n",
    "    top_indices = top_indices.squeeze().cpu().numpy()\n",
    "\n",
    "    outputs_fake = model(fake_patch_tensor)\n",
    "    probabilities_fake = torch.softmax(outputs_fake, dim=1)\n",
    "    top_probs_fake, top_indices_fake = torch.topk(probabilities_fake, TOP_K)\n",
    "    top_probs_fake = top_probs_fake.squeeze().cpu().numpy()\n",
    "    top_indices_fake = top_indices_fake.squeeze().cpu().numpy()\n",
    "\n",
    "print('Top predictions for adversarial patch:')\n",
    "for i in range(TOP_K):\n",
    "    class_idx = int(top_indices[i])\n",
    "    class_name = id_to_name.get(class_idx, f'Class {class_idx}')\n",
    "    prob = top_probs[i]\n",
    "    print(f'  {i+1}: {class_name} ({prob*100:.2f}%)')\n",
    "\n",
    "print('\\nTop predictions for fake patch:')\n",
    "for i in range(TOP_K):\n",
    "    class_idx = int(top_indices_fake[i])\n",
    "    class_name = id_to_name.get(class_idx, f'Class {class_idx}')\n",
    "    prob = top_probs_fake[i]\n",
    "    print(f'  {i+1}: {class_name} ({prob*100:.2f}%)')\n",
    "\n",
    "# Plot side by side\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(image)\n",
    "axs[0].axis('off')\n",
    "predicted_class = id_to_name.get(int(top_indices[0]), 'Unknown')\n",
    "axs[0].set_title(f'Adv Patch: {predicted_class}\\n({top_probs[0]*100:.2f}%)')\n",
    "\n",
    "axs[1].imshow(fake_patch_image)\n",
    "axs[1].axis('off')\n",
    "predicted_class_fake = id_to_name.get(int(top_indices_fake[0]), 'Unknown')\n",
    "axs[1].set_title(f'Fake Patch: {predicted_class_fake}\\n({top_probs_fake[0]*100:.2f}%)')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "traffic-signs-adversarial-attacks-Cofwj4W0-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
